{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljp46V5jxC_g"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from torch.utils.data import Subset\n",
        "import random"
      ],
      "metadata": {
        "id": "G8lssZYVOasi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Globals"
      ],
      "metadata": {
        "id": "78BEFE9CO1uW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    data_root = \"./data\"\n",
        "    model_save_path = \"./models\"\n",
        "    plot_save_path = \"./plots\"\n",
        "    os.makedirs(model_save_path, exist_ok=True)\n",
        "    os.makedirs(plot_save_path, exist_ok=True)\n",
        "\n",
        "    model_name = 'mobilenetv3' # resnet50, mobilenetv3, repnext\n",
        "    use_pretrained = False\n",
        "\n",
        "    ood_datasets = ['SVHN', 'CIFAR10', 'FashionMNIST', 'Flowers102', 'DTD',\n",
        "                    'FGVCAircraft', 'OxfordIIITPet', 'EuroSAT']\n",
        "    ood_dataset = 'DTD'\n",
        "\n",
        "    # data\n",
        "    batch_size = 256\n",
        "    num_workers = 4\n",
        "    image_size = 224\n",
        "    num_classes = 101\n",
        "\n",
        "    # standard training\n",
        "    learning_rate_std = 1e-3\n",
        "    epochs_std = 30\n",
        "\n",
        "    # energy-based fine tuning\n",
        "    learning_rate_energy = 1e-4\n",
        "    epochs_energy = 10\n",
        "    lambda_energy = 0.1\n",
        "    m_in = -11\n",
        "    m_out = -5\n",
        "\n",
        "    # GReg fine-tuning\n",
        "    use_grad_reg = False\n",
        "    lambda_grad = 1.0"
      ],
      "metadata": {
        "id": "HO9k171WO72b"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "sYZF4TScQdEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_energy_score(logits, T=1.0):\n",
        "    return -T * torch.logsumexp(logits / T, dim=1)\n",
        "\n",
        "def calculate_ood_metrics(id_scores, ood_scores):\n",
        "    scores = np.concatenate([id_scores, ood_scores])\n",
        "    scores = -scores # higher score = more confident (ID)\n",
        "\n",
        "    labels = np.concatenate(\n",
        "        [np.ones_like(id_scores), np.zeros_like(ood_scores)]\n",
        "    )\n",
        "\n",
        "    auroc = roc_auc_score(labels, scores)\n",
        "    aupr = average_precision_score(labels, scores)\n",
        "\n",
        "    # calculate FPR at 95% TPR\n",
        "    fpr, tpr, _ = roc_curve(labels, scores)\n",
        "    idx = np.searchsorted(tpr, 0.95)\n",
        "    fpr_at_95_tpr = fpr[idx] if idx < len(fpr) else 1.0\n",
        "\n",
        "    return auroc, aupr, fpr_at_95_tpr\n",
        "\n",
        "def plot_distributions(id_scores, ood_scores, ood_name, title, save_path):\n",
        "    plt.figure(figsize=(12, 7))\n",
        "    sns.kdeplot(data=-id_scores, label=f'ID (Food-101) mean: {-np.mean(id_scores):.2f}', fill=True)\n",
        "    sns.kdeplot(data=-ood_scores, label=f'OOD ({ood_name}) mean: {-np.mean(ood_scores):.2f}', fill=True)\n",
        "    plt.title(title, fontsize=16)\n",
        "    plt.xlabel(\"Score\", fontsize=12)\n",
        "    plt.ylabel(\"Frequency\", fontsize=12)\n",
        "    plt.legend()\n",
        "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "    plt.savefig(save_path)\n",
        "    print(f\"Distribution plot saved to {save_path}\")\n",
        "    plt.close()\n",
        "\n",
        "def get_ood_loader(dataset_name, transform, config, purpose):\n",
        "    print(f\"Loading OOD dataset: {dataset_name} ({purpose})\")\n",
        "\n",
        "    # for FashionMNIST we need to convert grayscale -> 3 channels\n",
        "    if dataset_name == 'FashionMNIST':\n",
        "        ood_transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=3),\n",
        "            *transform.transforms\n",
        "        ])\n",
        "    else:\n",
        "        ood_transform = transform\n",
        "\n",
        "    if dataset_name == 'SVHN':\n",
        "        ood_dataset = torchvision.datasets.SVHN(root=config.data_root, split='test', download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'CIFAR10':\n",
        "        ood_dataset = torchvision.datasets.CIFAR10(root=config.data_root, train=False, download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'FashionMNIST':\n",
        "        ood_dataset = torchvision.datasets.FashionMNIST(root=config.data_root, train=False, download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'Flowers102':\n",
        "        ood_dataset = torchvision.datasets.Flowers102(root=config.data_root, split='test', download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'DTD':\n",
        "        ood_dataset = torchvision.datasets.DTD(root=config.data_root, split='test', download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'FGVCAircraft':\n",
        "        ood_dataset = torchvision.datasets.FGVCAircraft(root=config.data_root, split='test', download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'OxfordIIITPet':\n",
        "        ood_dataset = torchvision.datasets.OxfordIIITPet(root=config.data_root, split='test', download=True, transform=ood_transform)\n",
        "    elif dataset_name == 'EuroSAT':\n",
        "        ood_dataset = torchvision.datasets.EuroSAT(root=config.data_root, download=True, transform=ood_transform)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown OOD dataset name: {dataset_name}\")\n",
        "\n",
        "    ood_loader = DataLoader(ood_dataset, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers, pin_memory=True)\n",
        "    print(f\"{dataset_name} ({purpose}) loader ready.\")\n",
        "    return ood_loader\n",
        "\n",
        "# for hyperparameter search\n",
        "def run_ood_evaluation(model, id_test_loader, ood_test_loader):\n",
        "    model.eval()\n",
        "    id_scores, ood_scores = [], []\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "        for inputs, _ in id_test_loader:\n",
        "            inputs = inputs.to(Config.device)\n",
        "            logits = model(inputs)\n",
        "            id_scores.extend(get_energy_score(logits).cpu().numpy())\n",
        "        for inputs, _ in ood_test_loader:\n",
        "            inputs = inputs.to(Config.device)\n",
        "            logits = model(inputs)\n",
        "            ood_scores.extend(get_energy_score(logits).cpu().numpy())\n",
        "    id_scores = np.array(id_scores)\n",
        "    ood_scores = np.array(ood_scores)\n",
        "    auroc, _, _ = calculate_ood_metrics(id_scores, ood_scores)\n",
        "    return auroc\n",
        "\n",
        "def run_energy_tuning_trial(model, id_loader, ood_loader, val_loader, ood_val_loader, epochs, lr, m_in, m_out):\n",
        "    criterion_ce = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "\n",
        "    best_auroc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        ood_iter = iter(ood_loader)\n",
        "        pbar = tqdm(id_loader, desc=f\"Trial epoch {epoch+1}/{epochs}\", leave=False)\n",
        "        for id_inputs, id_labels in pbar:\n",
        "            try:\n",
        "                ood_inputs, _ = next(ood_iter)\n",
        "            except StopIteration:\n",
        "                ood_iter = iter(ood_loader)\n",
        "                ood_inputs, _ = next(ood_iter)\n",
        "\n",
        "            id_inputs, id_labels = id_inputs.to(Config.device), id_labels.to(Config.device)\n",
        "            ood_inputs = ood_inputs.to(Config.device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                id_logits = model(id_inputs)\n",
        "                ood_logits = model(ood_inputs)\n",
        "                loss_ce = criterion_ce(id_logits, id_labels)\n",
        "                id_energy = get_energy_score(id_logits)\n",
        "                ood_energy = get_energy_score(ood_logits)\n",
        "                loss_energy = (torch.pow(torch.relu(id_energy - m_in), 2).mean() +\n",
        "                               torch.pow(torch.relu(m_out - ood_energy), 2).mean())\n",
        "                loss = loss_ce + Config.lambda_energy * loss_energy\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "        auroc = run_ood_evaluation(model, val_loader, ood_val_loader)\n",
        "        if auroc > best_auroc:\n",
        "            best_auroc = auroc\n",
        "\n",
        "    return best_auroc\n",
        "\n",
        "def objective(trial):\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
        "    m_in = trial.suggest_float(\"m_in\", -27.0, -8.0)\n",
        "    m_out = trial.suggest_float(\"m_out\", -7.0, -1.0)\n",
        "\n",
        "    print(f\"\\n--- Starting trial {trial.number} ---\")\n",
        "    print(f\"  Params: lr={lr:.6f}, m_in={m_in:.2f}, m_out={m_out:.2f}\")\n",
        "\n",
        "    model_search = create_model()\n",
        "    model_std_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_standard.pth\")\n",
        "    model_search.load_state_dict(torch.load(model_std_path, map_location=Config.device))\n",
        "\n",
        "    epochs_per_trial = 3\n",
        "    best_auroc = run_energy_tuning_trial(\n",
        "        model=model_search,\n",
        "        id_loader=id_train_loader,\n",
        "        ood_loader=ood_train_loader_energy,\n",
        "        val_loader=id_val_loader_subset,\n",
        "        ood_val_loader=ood_val_loader_subset,\n",
        "        epochs=epochs_per_trial,\n",
        "        lr=lr,\n",
        "        m_in=m_in,\n",
        "        m_out=m_out\n",
        "    )\n",
        "\n",
        "    print(f\"--- Trial {trial.number} finished --- AUROC: {best_auroc:.4f}\")\n",
        "    return best_auroc\n",
        "\n",
        "# GReg\n",
        "def get_gradient_norm(model, inputs):\n",
        "    inputs.requires_grad_(True)\n",
        "    logits = model(inputs)\n",
        "    energy_score = get_energy_score(logits)\n",
        "\n",
        "    grad_output = torch.ones_like(energy_score)\n",
        "    gradient = torch.autograd.grad(\n",
        "        outputs=energy_score,\n",
        "        inputs=inputs,\n",
        "        grad_outputs=grad_output,\n",
        "        create_graph=True,\n",
        "        retain_graph=True\n",
        "    )[0]\n",
        "\n",
        "    grad_norm = torch.linalg.norm(gradient.view(gradient.size(0), -1), dim=1)\n",
        "    inputs.requires_grad_(False)\n",
        "    return grad_norm\n",
        "\n",
        "# CORES\n",
        "# consider both logits and internal feature maps\n",
        "# IDs produce stronger and more frequent responses for important kernels than OODs\n",
        "# => internal filters fire strongly and frequently for ID features => high RM and RF\n",
        "class CORESScorer:\n",
        "    def __init__(self, model, k_percent=0.2):\n",
        "        self.model = model\n",
        "        self.k = k_percent          # % kernels to select\n",
        "        self.feature_maps = {}      # store output of the layer we are interested in\n",
        "        self.hooks = []             # store listeners\n",
        "\n",
        "        # get key layers\n",
        "        if isinstance(model, MobileNetV3):\n",
        "            self.final_conv_name = 'final_conv'\n",
        "            self.fc_layer = model.head[1]\n",
        "        elif isinstance(model, RepNeXt):\n",
        "            self.final_conv_name = 'layer3'\n",
        "            self.fc_layer = model.linear\n",
        "\n",
        "        # listen to the final conv layer\n",
        "        self._register_hook(self.final_conv_name)\n",
        "\n",
        "    # find the layer\n",
        "    def _register_hook(self, layer_name):\n",
        "        for name, module in self.model.named_modules():\n",
        "            if name == layer_name:\n",
        "                target_layer = module\n",
        "                break\n",
        "        else:\n",
        "            raise NameError(f\"Layer {layer_name} not found\")\n",
        "\n",
        "        handle = target_layer.register_forward_hook(self._hook_fn(layer_name))\n",
        "        self.hooks.append(handle)\n",
        "\n",
        "    # listener fn\n",
        "    def _hook_fn(self, layer_name):\n",
        "        def hook(module, input, output):\n",
        "            self.feature_maps[layer_name] = output\n",
        "        return hook\n",
        "\n",
        "    # sample-relevant kernel selection\n",
        "    def _get_selected_kernels(self, logits):\n",
        "        # find the most and least likely class predictions\n",
        "        # take logits and find class index with highest and lowest score for each img in batch\n",
        "        c_max = torch.argmax(logits, dim=1)\n",
        "        c_min = torch.argmin(logits, dim=1)\n",
        "\n",
        "        if self.fc_layer.weight.dim() == 4:\n",
        "            fc_weights = self.fc_layer.weight.data.squeeze()\n",
        "        else:\n",
        "            fc_weights = self.fc_layer.weight.data\n",
        "\n",
        "        num_kernels = self.feature_maps[self.final_conv_name].shape[1]\n",
        "        k_num = max(1, int(num_kernels * self.k))\n",
        "\n",
        "        selected_indices = []\n",
        "        for i in range(logits.shape[0]):\n",
        "            out_channels = fc_weights.shape[0]\n",
        "            weights_max = fc_weights[c_max[i] % out_channels]\n",
        "            weights_min = fc_weights[c_min[i] % out_channels]\n",
        "\n",
        "            # backtracking\n",
        "            # find k_num channels (kernels) with strongest weights (most influence) for both c_max and c_min predictions\n",
        "            _, top_indices = torch.topk(weights_max, k_num)\n",
        "            _, bot_indices = torch.topk(weights_min, k_num)\n",
        "\n",
        "            # combine them to get sample-relevant kernels for this image\n",
        "            indices = torch.cat([top_indices, bot_indices])\n",
        "            selected_indices.append(torch.unique(indices))\n",
        "\n",
        "        return selected_indices\n",
        "\n",
        "    def _calculate_score(self, feature_map_batch, selected_indices_batch):\n",
        "        batch_scores = []\n",
        "        for i in range(feature_map_batch.shape[0]):\n",
        "            feature_map = feature_map_batch[i]\n",
        "            selected_indices = selected_indices_batch[i]\n",
        "\n",
        "            # keep only selected kernels\n",
        "            selected_features = feature_map[selected_indices]\n",
        "\n",
        "            # find peak positive and negative response for each kernel\n",
        "            max_responses = torch.amax(selected_features, dim=(1, 2))\n",
        "            min_responses = torch.amin(selected_features, dim=(1, 2))\n",
        "\n",
        "            # score components computation\n",
        "            rm_pos = torch.mean(max_responses.clamp(min=1e-6))                  # response magnitude positive: avg of highest values\n",
        "            rm_neg = torch.mean((-min_responses).clamp(min=1e-6))               # response magnitude negative: avg of negated lowest values\n",
        "            rf_pos = torch.mean((max_responses > 0).float()).clamp(min=1e-6)    # response frequency positive: fraction of selected kernels that had a positive peak response\n",
        "            rf_neg = torch.mean((min_responses < 0).float()).clamp(min=1e-6)    # response frequency negative: fraction of selected kernels that had a negative peak response\n",
        "\n",
        "            # combine them to get the final score (sum of logs = product)\n",
        "            score = torch.log(rm_pos) + torch.log(rm_neg) + torch.log(rf_pos) + torch.log(rf_neg)\n",
        "            batch_scores.append(score.item())\n",
        "\n",
        "        return np.array(batch_scores)\n",
        "\n",
        "    def __call__(self, x):\n",
        "        self.feature_maps.clear()\n",
        "        logits = self.model(x)\n",
        "\n",
        "        kernel_indices = self._get_selected_kernels(logits)\n",
        "        final_conv_maps = self.feature_maps[self.final_conv_name]\n",
        "\n",
        "        scores = self._calculate_score(final_conv_maps, kernel_indices)\n",
        "        return scores\n",
        "\n",
        "    def close(self):\n",
        "        for handle in self.hooks:\n",
        "            handle.remove()"
      ],
      "metadata": {
        "id": "mbEV7aqdQa3T"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Networks"
      ],
      "metadata": {
        "id": "00kzzrKBPZl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RepNeXt"
      ],
      "metadata": {
        "id": "Pn37r2PSPf1K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RepNeXtBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super().__init__()\n",
        "        self.conv_3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.conv_1x1 = nn.Conv2d(out_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = self.act(self.bn1(self.conv_3x3(x)))\n",
        "        out = self.bn2(self.conv_1x1(out))\n",
        "        out += self.shortcut(x)\n",
        "        return self.act(out)\n",
        "\n",
        "class RepNeXt(nn.Module):\n",
        "    def __init__(self, num_blocks, num_classes=101):\n",
        "        super().__init__()\n",
        "        self.in_planes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.act = nn.ReLU()\n",
        "        self.layer1 = self._make_layer(64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(256, num_blocks[2], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.linear = nn.Linear(256, num_classes)\n",
        "\n",
        "    def _make_layer(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for s in strides:\n",
        "            layers.append(RepNeXtBlock(self.in_planes, planes, s))\n",
        "            self.in_planes = planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def get_features(self, x):\n",
        "        out = self.act(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avgpool(out)\n",
        "        return out.view(out.size(0), -1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.get_features(x)\n",
        "        logits = self.linear(features)\n",
        "        return logits, features"
      ],
      "metadata": {
        "id": "_RlScp2nP8bj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MobileNetV3"
      ],
      "metadata": {
        "id": "FfHtbbvdPdjq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SqueezeExcite(nn.Module):\n",
        "    def __init__(self, in_channels, reduced_dim):\n",
        "        super().__init__()\n",
        "        self.se = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, reduced_dim, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Conv2d(reduced_dim, in_channels, 1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * self.se(x)\n",
        "\n",
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, expansion_factor, use_se=True):\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        hidden_dim = in_channels * expansion_factor\n",
        "        self.use_res_connect = self.stride == 1 and in_channels == out_channels\n",
        "\n",
        "        layers = []\n",
        "        # expansion phase with 1x1 pointwise conv\n",
        "        if expansion_factor != 1:\n",
        "            layers.append(nn.Conv2d(in_channels, hidden_dim, 1, 1, 0, bias=False))\n",
        "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
        "            layers.append(nn.SiLU())\n",
        "\n",
        "        # depthwise conv\n",
        "        layers.extend([\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, kernel_size//2, groups=hidden_dim, bias=False),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.SiLU(),\n",
        "        ])\n",
        "\n",
        "        # squeeze-and-excite layer\n",
        "        if use_se:\n",
        "            layers.append(SqueezeExcite(hidden_dim, in_channels // 4))\n",
        "\n",
        "        # projection phase with 1x1 pointwise conv\n",
        "        layers.append(nn.Conv2d(hidden_dim, out_channels, 1, 1, 0, bias=False))\n",
        "        layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.conv = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "class MobileNetV3(nn.Module):\n",
        "    def __init__(self, num_classes=101):\n",
        "        super().__init__()\n",
        "        config = [\n",
        "            # expansion, out_channels, num_repeats, kernel_size, stride, use_se\n",
        "            [1, 16, 1, 3, 1, True],\n",
        "            [4, 24, 2, 3, 2, False],\n",
        "            [3, 40, 3, 5, 2, True],\n",
        "            [6, 80, 3, 3, 2, False],\n",
        "            [6, 112, 2, 3, 1, True],\n",
        "            [6, 160, 3, 5, 2, True],\n",
        "        ]\n",
        "\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.SiLU(),\n",
        "        )\n",
        "\n",
        "        in_channels = 16\n",
        "        blocks = []\n",
        "        for expansion, out_channels, num_repeats, kernel_size, stride, use_se in config:\n",
        "            for i in range(num_repeats):\n",
        "                block_stride = stride if i == 0 else 1\n",
        "                blocks.append(InvertedResidual(in_channels, out_channels, kernel_size, block_stride, expansion, use_se))\n",
        "                in_channels = out_channels\n",
        "\n",
        "        self.blocks = nn.Sequential(*blocks)\n",
        "\n",
        "        self.final_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 960, kernel_size=1, stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(960),\n",
        "            nn.SiLU()\n",
        "        )\n",
        "\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(960, 1280, 1),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Conv2d(1280, num_classes, 1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, return_features=False):\n",
        "        x = self.stem(x)\n",
        "        features = self.blocks(x)\n",
        "        x = self.final_conv(features)\n",
        "        x = self.head(x)\n",
        "        logits = x.view(x.size(0), -1)\n",
        "\n",
        "        if return_features:\n",
        "            return logits, features\n",
        "        return logits"
      ],
      "metadata": {
        "id": "v6m_-l1TPhdG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model creation"
      ],
      "metadata": {
        "id": "NzcMYttCQE5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    if Config.model_name == 'resnet50':\n",
        "        print(f\"Creating ResNet50 model {f'(pretrained)' if Config.use_pretrained else None}\")\n",
        "        weights = models.ResNet50_Weights.IMAGENET1K_V2 if Config.use_pretrained else None\n",
        "        model = models.resnet50(weights=weights)\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, Config.num_classes)\n",
        "    elif Config.model_name == 'mobilenetv3':\n",
        "        print(\"Creating MobileNetV3 model\")\n",
        "        model = MobileNetV3(num_classes=Config.num_classes)\n",
        "    elif Config.model_name == 'repnext':\n",
        "        print('Creating RepNeXt model')\n",
        "        model = RepNeXt(num_blocks=[2, 2, 2], num_classes=Config.num_classes)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown model {Config.model_name}; choose among resnet50, mobilnetv3, repnext\")\n",
        "    return model.to(Config.device)"
      ],
      "metadata": {
        "id": "IrGZxIBfQHLV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train\n"
      ],
      "metadata": {
        "id": "xEAp-A4uRl-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, epochs, lr, save_path):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Training]\")\n",
        "        for inputs, labels in pbar:\n",
        "            inputs, labels = inputs.to(Config.device), labels.to(Config.device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            pbar.set_postfix(loss=f'{running_loss/len(pbar):.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Validation]\"):\n",
        "                inputs, labels = inputs.to(Config.device), labels.to(Config.device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch+1} | Validation accuracy: {acc:.2f}% | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            print(f\"New best accuracy, saving model to {save_path}\")\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "def train_energy(model, id_loader, ood_loader, val_loader, ood_val_loader, epochs, lr, save_path, use_grad_reg=False):\n",
        "    criterion_ce = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    scaler = torch.amp.GradScaler('cuda')\n",
        "    best_auroc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        ood_iter = iter(ood_loader)\n",
        "        pbar = tqdm(id_loader, desc=f\"Epoch {epoch+1}/{epochs} [Energy training]\")\n",
        "        for id_inputs, id_labels in pbar:\n",
        "            try:\n",
        "                ood_inputs, _ = next(ood_iter)\n",
        "            except StopIteration:\n",
        "                ood_iter = iter(ood_loader)\n",
        "                ood_inputs, _ = next(ood_iter)\n",
        "\n",
        "            id_inputs, id_labels = id_inputs.to(Config.device), id_labels.to(Config.device)\n",
        "            ood_inputs = ood_inputs.to(Config.device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.amp.autocast(device_type='cuda'):\n",
        "                id_logits = model(id_inputs)\n",
        "                ood_logits = model(ood_inputs)\n",
        "\n",
        "                loss_ce = criterion_ce(id_logits, id_labels)\n",
        "                id_energy = get_energy_score(id_logits)\n",
        "                ood_energy = get_energy_score(ood_logits)\n",
        "\n",
        "                loss_energy = (torch.pow(torch.relu(id_energy - Config.m_in), 2).mean() +\n",
        "                               torch.pow(torch.relu(Config.m_out - ood_energy), 2).mean())\n",
        "\n",
        "                loss = loss_ce + Config.lambda_energy * loss_energy\n",
        "\n",
        "                if use_grad_reg:\n",
        "                    loss_grad_id = torch.tensor(0.0, device=Config.device)\n",
        "                    loss_grad_ood = torch.tensor(0.0, device=Config.device)\n",
        "\n",
        "                    id_grad_norm = get_gradient_norm(model, id_inputs)\n",
        "                    ood_grad_norm = get_gradient_norm(model, ood_inputs)\n",
        "\n",
        "                    # apply loss only to well-behaved samples\n",
        "                    id_mask = id_energy < Config.m_in\n",
        "                    if id_mask.any():\n",
        "                        loss_grad_id = (id_grad_norm[id_mask]**2).mean()\n",
        "                    ood_mask = ood_energy > Config.m_out\n",
        "                    if ood_mask.any():\n",
        "                        loss_grad_ood = (ood_grad_norm[ood_mask]**2).mean()\n",
        "                    loss_grad = loss_grad_id + loss_grad_ood\n",
        "\n",
        "                    loss += Config.lambda_grad * loss_grad\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            postfix_dict = {\n",
        "                'loss': f'{running_loss/len(pbar):.4f}',\n",
        "                'ce': f'{loss_ce.item():.4f}',\n",
        "                'en': f'{loss_energy.item():.4f}'\n",
        "            }\n",
        "            if use_grad_reg:\n",
        "                postfix_dict['grad'] = f'{loss_grad.item():.4f}'\n",
        "            pbar.set_postfix(postfix_dict)\n",
        "\n",
        "        # validation on OOD metrics\n",
        "        print(f\"\\n--- Evaluating after epoch {epoch+1} ---\")\n",
        "        plot_path_epoch = os.path.join(Config.plot_save_path, f\"energy_dist_epoch_{epoch+1}.png\")\n",
        "        val_acc, auroc, _, _ = evaluate_model(model, val_loader, ood_val_loader, \"Energy validation\", plot_save_path=plot_path_epoch)\n",
        "        print(f\"--- Current val acc: {val_acc:.2f}%, AUROC: {auroc:.4f} ---\")\n",
        "        if auroc > best_auroc:\n",
        "            best_auroc = auroc\n",
        "            print(f\"New best AUROC, saving model to {save_path}\")\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "        scheduler.step()"
      ],
      "metadata": {
        "id": "4qyzc7gpRnoG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "0hWXG3t2Ry2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_old(model, id_test_loader, ood_test_loader, eval_name=\"Evaluation\", plot_save_path=None, score_type='energy'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "        for inputs, labels in tqdm(id_test_loader, desc=f\"{eval_name} [Accuracy]\"):\n",
        "            inputs, labels = inputs.to(Config.device), labels.to(Config.device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"\\n{eval_name} - Classification accuracy on ID test set: {acc:.2f}%\")\n",
        "\n",
        "    id_scores, ood_scores = [], []\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "        for inputs, _ in tqdm(id_test_loader, desc=f\"{eval_name} [OOD scores - ID]\"):\n",
        "            inputs = inputs.to(Config.device)\n",
        "            logits = model(inputs)\n",
        "            id_scores.extend(get_energy_score(logits).cpu().numpy())\n",
        "\n",
        "        for inputs, _ in tqdm(ood_test_loader, desc=f\"{eval_name} [OOD scores - OOD]\"):\n",
        "            inputs = inputs.to(Config.device)\n",
        "            logits = model(inputs)\n",
        "            ood_scores.extend(get_energy_score(logits).cpu().numpy())\n",
        "\n",
        "    id_scores = np.array(id_scores)\n",
        "    ood_scores = np.array(ood_scores)\n",
        "    auroc, aupr, fpr_at_95_tpr = calculate_ood_metrics(id_scores, ood_scores)\n",
        "\n",
        "    print(f\"{eval_name} - OOD detection performance:\")\n",
        "    print(f\"  AUROC: {auroc:.4f}\")\n",
        "    print(f\"  AUPR: {aupr:.4f}\")\n",
        "    print(f\"  FPR @ 95% TPR: {fpr_at_95_tpr:.4f}\")\n",
        "\n",
        "    if plot_save_path:\n",
        "        plot_distributions(id_scores, ood_scores, Config.ood_dataset, f\"Energy score distribution ({eval_name})\", plot_save_path)\n",
        "\n",
        "    return acc, auroc, aupr, fpr_at_95_tpr"
      ],
      "metadata": {
        "id": "uEJpT-3SR18k"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, id_test_loader, ood_test_loader, eval_name=\"Evaluation\", plot_save_path=None, score_type='energy'):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "        for inputs, labels in tqdm(id_test_loader, desc=f\"{eval_name} [Accuracy]\"):\n",
        "            inputs, labels = inputs.to(Config.device), labels.to(Config.device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"\\n{eval_name} - Classification accuracy on ID test set: {acc:.2f}%\")\n",
        "\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "        for inputs, labels in tqdm(id_test_loader, desc=f\"{eval_name} [Accuracy]\"):\n",
        "            inputs, labels = inputs.to(Config.device), labels.to(Config.device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    acc = 100 * correct / total\n",
        "    print(f\"\\n{eval_name} - Classification accuracy on ID test set: {acc:.2f}%\")\n",
        "\n",
        "\n",
        "    id_scores, ood_scores = [], []\n",
        "\n",
        "    if score_type == 'cores':\n",
        "        scorer = CORESScorer(model)\n",
        "\n",
        "    with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
        "        for loader, score_list in [(id_test_loader, id_scores), (ood_test_loader, ood_scores)]:\n",
        "            desc = f\"{eval_name} [Scores - {'ID' if loader==id_test_loader else 'OOD'}]\"\n",
        "            for inputs, _ in tqdm(loader, desc=desc):\n",
        "                inputs = inputs.to(Config.device)\n",
        "\n",
        "                if score_type == 'energy':\n",
        "                    logits = model(inputs)\n",
        "                    scores = get_energy_score(logits).cpu().numpy()\n",
        "                elif score_type == 'cores':\n",
        "                    scores = scorer(inputs)\n",
        "                else:\n",
        "                    raise ValueError(\"score_type must be 'energy' or 'cores'\")\n",
        "\n",
        "                score_list.extend(scores)\n",
        "\n",
        "    if score_type == 'cores':\n",
        "        scorer.close()\n",
        "\n",
        "    id_scores, ood_scores = np.array(id_scores), np.array(ood_scores)\n",
        "\n",
        "    if score_type == 'cores':\n",
        "        id_scores = -id_scores\n",
        "        ood_scores = -ood_scores\n",
        "\n",
        "    auroc, aupr, fpr95 = calculate_ood_metrics(id_scores, ood_scores)\n",
        "\n",
        "    print(f\"{eval_name} - OOD detection performance ({score_type.upper()}):\")\n",
        "    print(f\"  AUROC: {auroc:.4f}\")\n",
        "    print(f\"  AUPR: {aupr:.4f}\")\n",
        "    print(f\"  FPR @ 95% TPR: {fpr95:.4f}\")\n",
        "\n",
        "    if plot_save_path:\n",
        "        plot_title = f\"{score_type.capitalize()} Score Distribution ({eval_name})\"\n",
        "        plot_distributions(id_scores, ood_scores, Config.ood_dataset, plot_title, plot_save_path)\n",
        "\n",
        "    return acc, auroc, aupr, fpr95"
      ],
      "metadata": {
        "id": "UN_7jMxR6PCM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "S2OhXxRNROC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(Config.image_size),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(Config.image_size),\n",
        "    transforms.ToTensor(),\n",
        "    normalize,\n",
        "])\n",
        "\n",
        "food_train_dataset = torchvision.datasets.Food101(root=Config.data_root, split='train', download=True, transform=transform_train)\n",
        "food_test_dataset = torchvision.datasets.Food101(root=Config.data_root, split='test', download=True, transform=transform_test)\n",
        "\n",
        "id_train_loader = DataLoader(food_train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers, pin_memory=True)\n",
        "id_test_loader = DataLoader(food_test_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers, pin_memory=True)\n",
        "\n",
        "ood_train_loader_energy = get_ood_loader(Config.ood_dataset, transform_train, Config, 'train')\n",
        "ood_test_loader = get_ood_loader(Config.ood_dataset, transform_test, Config, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7QSavzaRNWj",
        "outputId": "2729b1a7-03c2-49bd-f232-b2fe56220c93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading OOD dataset: DTD (train)\n",
            "DTD (train) loader ready.\n",
            "Loading OOD dataset: DTD (test)\n",
            "DTD (test) loader ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main"
      ],
      "metadata": {
        "id": "wrWB7hGtR2Ui"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "nfgvRaKgVLnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_std = create_model()\n",
        "model_std_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_standard.pth\")\n",
        "\n",
        "if os.path.exists(model_std_path):\n",
        "    print(f\"Loading pre-trained standard model from {model_std_path}\")\n",
        "    model_std.load_state_dict(torch.load(model_std_path, map_location=Config.device))\n",
        "else:\n",
        "    print(\"No pre-trained model found, starting training...\")\n",
        "    train(\n",
        "        model=model_std,\n",
        "        train_loader=id_train_loader,\n",
        "        val_loader=id_test_loader,\n",
        "        epochs=Config.epochs_std,\n",
        "        lr=Config.learning_rate_std,\n",
        "        save_path=model_std_path\n",
        "    )\n",
        "    model_std.load_state_dict(torch.load(model_std_path, map_location=Config.device))\n",
        "\n",
        "print(\"\\nEvaluating baseline model\")\n",
        "acc, auroc, aupr, fpr95 = evaluate_model(\n",
        "    model=model_std,\n",
        "    id_test_loader=id_test_loader,\n",
        "    ood_test_loader=ood_test_loader,\n",
        "    eval_name=\"Baseline model\",\n",
        "    plot_save_path=os.path.join(Config.plot_save_path, \"baseline_distribution.png\")\n",
        ")"
      ],
      "metadata": {
        "id": "rR4qWKKkVS2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Energy-based fine-tuning"
      ],
      "metadata": {
        "id": "fB9hZhiIVNGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_std_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_standard.pth\")\n",
        "model_energy_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_energy.pth\")\n",
        "\n",
        "model_energy = create_model()\n",
        "print(f\"Loading weights from baseline model: {model_std_path}\")\n",
        "model_energy.load_state_dict(torch.load(model_std_path, map_location=Config.device))\n",
        "\n",
        "# freeze all layers\n",
        "for param in model_energy.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# unfreeze the head\n",
        "for param in model_energy.head.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "print(\"Starting energy-based fine-tuning against {Config.ood_dataset}\")\n",
        "train_energy(\n",
        "    model=model_energy,\n",
        "    id_loader=id_train_loader,\n",
        "    ood_loader=ood_train_loader_energy,\n",
        "    val_loader=id_test_loader,\n",
        "    ood_val_loader=ood_test_loader,\n",
        "    epochs=Config.epochs_energy,\n",
        "    lr=Config.learning_rate_energy,\n",
        "    save_path=model_energy_path,\n",
        "    use_grad_reg=Config.use_grad_reg\n",
        ")\n",
        "\n",
        "print(f\"Loading best energy model from: {model_energy_path}\")\n",
        "model_energy.load_state_dict(torch.load(model_energy_path, map_location=Config.device))\n",
        "\n",
        "print(\"\\nEvaluating final energy model\")\n",
        "evaluate_model(\n",
        "    model=model_energy,\n",
        "    id_test_loader=id_test_loader,\n",
        "    ood_test_loader=ood_test_loader,\n",
        "    eval_name=\"Energy model\",\n",
        "    plot_save_path=os.path.join(Config.plot_save_path, \"energy_tuned_distribution.png\")\n",
        ")"
      ],
      "metadata": {
        "id": "fLpbvLcrR1H3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Results"
      ],
      "metadata": {
        "id": "ugRGuVdz-9Z-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_standard.pth\")\n",
        "#model_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_energy.pth\")\n",
        "\n",
        "print(f\"--- Evaluating model: {model_path} ---\")\n",
        "\n",
        "model_to_eval = create_model()\n",
        "model_to_eval.load_state_dict(torch.load(model_path, map_location=Config.device))\n",
        "model_to_eval.eval()\n",
        "\n",
        "# eval acc\n",
        "overall_accuracy = 0\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(id_test_loader, desc=\"Calculating accuracy\"):\n",
        "        outputs = model_to_eval(inputs.to(Config.device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(Config.device)).sum().item()\n",
        "overall_accuracy = 100 * correct / total\n",
        "\n",
        "# compute OOD metrics\n",
        "results = []\n",
        "model_short_name = os.path.basename(model_path).replace('.pth', '')\n",
        "\n",
        "id_scores = []\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in tqdm(id_test_loader, desc=\"Calculating ID scores\"):\n",
        "        id_scores.extend(get_energy_score(model_to_eval(inputs.to(Config.device))).cpu().numpy())\n",
        "id_scores = np.array(id_scores)\n",
        "\n",
        "for ood_name in Config.ood_datasets:\n",
        "    ood_loader_eval = get_ood_loader(ood_name, transform_test, Config, 'test')\n",
        "\n",
        "    ood_scores = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in tqdm(ood_loader_eval, desc=f\"OOD scores for {ood_name}\"):\n",
        "            ood_scores.extend(get_energy_score(model_to_eval(inputs.to(Config.device))).cpu().numpy())\n",
        "\n",
        "    ood_scores = np.array(ood_scores)\n",
        "    auroc, aupr, fpr95 = calculate_ood_metrics(id_scores, ood_scores)\n",
        "    results.append({\"OOD dataset\": ood_name, \"AUROC\": auroc, \"AUPR\": aupr, \"FPR@95TPR\": fpr95})\n",
        "\n",
        "    # plot\n",
        "    plot_save_path = os.path.join(Config.plot_save_path, f\"{model_short_name}_{ood_name}.png\")\n",
        "    plot_title = f\"Energy distribution ({model_short_name}): Food-101 vs {ood_name}\"\n",
        "    plot_distributions(id_scores, ood_scores, ood_name, plot_title, plot_save_path)\n",
        "\n",
        "\n",
        "# summary table\n",
        "print(f\"\\n--- Performance summary: {model_path} ---\")\n",
        "print(f\"Classification accuracy (Food-101): {overall_accuracy:.2f}%\")\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False, float_format=\"%.4f\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6hXbzV-qKWI",
        "outputId": "5d44d3b9-3a73-4ff4-c5e3-a2ac646488c6",
        "collapsed": true
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating model: ./models/mobilenetv3_standard.pth ---\n",
            "Creating MobileNetV3 model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating accuracy: 100%|| 99/99 [00:27<00:00,  3.65it/s]\n",
            "Calculating ID scores (once): 100%|| 99/99 [00:26<00:00,  3.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading OOD dataset: SVHN (test)\n",
            "SVHN (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for SVHN: 100%|| 102/102 [00:11<00:00,  8.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_SVHN.png\n",
            "Loading OOD dataset: CIFAR10 (test)\n",
            "CIFAR10 (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for CIFAR10: 100%|| 40/40 [00:04<00:00,  8.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_CIFAR10.png\n",
            "Loading OOD dataset: FashionMNIST (test)\n",
            "FashionMNIST (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for FashionMNIST: 100%|| 40/40 [00:05<00:00,  7.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_FashionMNIST.png\n",
            "Loading OOD dataset: Flowers102 (test)\n",
            "Flowers102 (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for Flowers102: 100%|| 25/25 [00:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_Flowers102.png\n",
            "Loading OOD dataset: DTD (test)\n",
            "DTD (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for DTD: 100%|| 8/8 [00:02<00:00,  2.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_DTD.png\n",
            "Loading OOD dataset: FGVCAircraft (test)\n",
            "FGVCAircraft (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for FGVCAircraft: 100%|| 14/14 [00:12<00:00,  1.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_FGVCAircraft.png\n",
            "Loading OOD dataset: OxfordIIITPet (test)\n",
            "OxfordIIITPet (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for OxfordIIITPet: 100%|| 15/15 [00:05<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_OxfordIIITPet.png\n",
            "Loading OOD dataset: EuroSAT (test)\n",
            "EuroSAT (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for EuroSAT: 100%|| 106/106 [00:12<00:00,  8.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_standard_EuroSAT.png\n",
            "\n",
            "--- Performance summary: ./models/mobilenetv3_standard.pth ---\n",
            "Classification accuracy (Food-101): 67.56%\n",
            "  OOD dataset  AUROC   AUPR  FPR@95TPR\n",
            "         SVHN 0.9992 0.9992     0.0020\n",
            "      CIFAR10 0.9948 0.9978     0.0217\n",
            " FashionMNIST 1.0000 1.0000     0.0000\n",
            "   Flowers102 0.8825 0.9673     0.5097\n",
            "          DTD 0.9353 0.9935     0.2532\n",
            " FGVCAircraft 0.9961 0.9995     0.0177\n",
            "OxfordIIITPet 0.9239 0.9878     0.4064\n",
            "      EuroSAT 0.9997 0.9997     0.0005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_standard.pth\")\n",
        "model_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_energy.pth\")\n",
        "\n",
        "print(f\"--- Evaluating model: {os.path.basename(model_path)} with CORES scores ---\")\n",
        "model_to_eval = create_model()\n",
        "model_to_eval.load_state_dict(torch.load(model_path, map_location=Config.device))\n",
        "model_to_eval.eval()\n",
        "model_short_name = os.path.basename(model_path).replace('.pth', '')\n",
        "\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in tqdm(id_test_loader, desc=\"Calculating accuracy\"):\n",
        "        outputs = model_to_eval(inputs.to(Config.device))\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels.to(Config.device)).sum().item()\n",
        "overall_accuracy = 100 * correct / total\n",
        "\n",
        "id_scores = []\n",
        "scorer = CORESScorer(model_to_eval)\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in tqdm(id_test_loader, desc=\"Calculating ID scores (CORES)\"):\n",
        "        inputs = inputs.to(Config.device)\n",
        "        id_scores.extend(scorer(inputs))\n",
        "id_scores = np.array(id_scores)\n",
        "\n",
        "results = []\n",
        "for ood_name in Config.ood_datasets:\n",
        "    ood_loader_eval = get_ood_loader(ood_name, transform_test, Config, 'test')\n",
        "    ood_scores = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in tqdm(ood_loader_eval, desc=f\"OOD scores for {ood_name}\"):\n",
        "            inputs = inputs.to(Config.device)\n",
        "            ood_scores.extend(scorer(inputs))\n",
        "    ood_scores = np.array(ood_scores)\n",
        "\n",
        "    metric_id_scores = -id_scores\n",
        "    metric_ood_scores = -ood_scores\n",
        "    auroc, aupr, fpr95 = calculate_ood_metrics(metric_id_scores, metric_ood_scores)\n",
        "    results.append({\"OOD dataset\": ood_name, \"AUROC\": auroc, \"AUPR\": aupr, \"FPR@95TPR\": fpr95})\n",
        "\n",
        "    plot_save_path = os.path.join(Config.plot_save_path, f\"{model_short_name}_{ood_name}_cores.png\")\n",
        "    plot_title = f\"CORES distribution ({model_short_name}): Food-101 vs {ood_name}\"\n",
        "    plot_distributions(metric_id_scores, metric_ood_scores, ood_name, plot_title, plot_save_path)\n",
        "\n",
        "scorer.close()\n",
        "\n",
        "print(f\"\\n--- Performance summary: {os.path.basename(model_path)} (CORES) ---\")\n",
        "print(f\"Classification accuracy (Food-101): {overall_accuracy:.2f}%\")\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string(index=False, float_format=\"%.4f\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0GoajOo8O74",
        "outputId": "e1f48902-fb47-4cfa-c601-1d2c7d19b583"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Evaluating model: mobilenetv3_energy.pth with CORES scores ---\n",
            "Creating MobileNetV3 model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating accuracy: 100%|| 99/99 [00:26<00:00,  3.78it/s]\n",
            "Calculating ID scores (CORES): 100%|| 99/99 [00:25<00:00,  3.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading OOD dataset: SVHN (test)\n",
            "SVHN (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for SVHN: 100%|| 102/102 [00:16<00:00,  6.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_SVHN_cores.png\n",
            "Loading OOD dataset: CIFAR10 (test)\n",
            "CIFAR10 (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for CIFAR10: 100%|| 40/40 [00:07<00:00,  5.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_CIFAR10_cores.png\n",
            "Loading OOD dataset: FashionMNIST (test)\n",
            "FashionMNIST (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for FashionMNIST: 100%|| 40/40 [00:06<00:00,  5.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_FashionMNIST_cores.png\n",
            "Loading OOD dataset: Flowers102 (test)\n",
            "Flowers102 (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for Flowers102: 100%|| 25/25 [00:08<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_Flowers102_cores.png\n",
            "Loading OOD dataset: DTD (test)\n",
            "DTD (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for DTD: 100%|| 8/8 [00:03<00:00,  2.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_DTD_cores.png\n",
            "Loading OOD dataset: FGVCAircraft (test)\n",
            "FGVCAircraft (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for FGVCAircraft: 100%|| 14/14 [00:12<00:00,  1.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_FGVCAircraft_cores.png\n",
            "Loading OOD dataset: OxfordIIITPet (test)\n",
            "OxfordIIITPet (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for OxfordIIITPet: 100%|| 15/15 [00:05<00:00,  2.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_OxfordIIITPet_cores.png\n",
            "Loading OOD dataset: EuroSAT (test)\n",
            "EuroSAT (test) loader ready.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "OOD scores for EuroSAT: 100%|| 106/106 [00:17<00:00,  6.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution plot saved to ./plots/mobilenetv3_energy_EuroSAT_cores.png\n",
            "\n",
            "--- Performance summary: mobilenetv3_energy.pth (CORES) ---\n",
            "Classification accuracy (Food-101): 76.00%\n",
            "  OOD dataset  AUROC   AUPR  FPR@95TPR\n",
            "         SVHN 0.9998 0.9998     0.0001\n",
            "      CIFAR10 0.9949 0.9981     0.0123\n",
            " FashionMNIST 0.9999 1.0000     0.0003\n",
            "   Flowers102 0.9204 0.9793     0.4329\n",
            "          DTD 0.9836 0.9986     0.0803\n",
            " FGVCAircraft 0.9922 0.9989     0.0324\n",
            "OxfordIIITPet 0.8052 0.9657     0.7296\n",
            "      EuroSAT 0.9994 0.9994     0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter search"
      ],
      "metadata": {
        "id": "EdqINYpj-Jog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Creating validation subsets for Optuna search...\")\n",
        "ood_search_dataset = get_ood_loader(Config.ood_dataset, transform_test, Config, 'test').dataset\n",
        "\n",
        "val_subset_fraction = 0.2\n",
        "id_test_indices = random.sample(range(len(food_test_dataset)), int(len(food_test_dataset) * val_subset_fraction))\n",
        "ood_test_indices = random.sample(range(len(ood_search_dataset)), int(len(ood_search_dataset) * val_subset_fraction))\n",
        "\n",
        "id_val_subset = Subset(food_test_dataset, id_test_indices)\n",
        "ood_val_subset = Subset(ood_search_dataset, ood_test_indices)\n",
        "\n",
        "id_val_loader_subset = DataLoader(id_val_subset, batch_size=Config.batch_size, num_workers=Config.num_workers)\n",
        "ood_val_loader_subset = DataLoader(ood_val_subset, batch_size=Config.batch_size, num_workers=Config.num_workers)\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(f\"Best trial number: {study.best_trial.number}\")\n",
        "print(f\"Best AUROC: {study.best_value:.4f}\")\n",
        "print(\"Best hyperparameters found:\", study.best_params)"
      ],
      "metadata": {
        "id": "B2LtNaPSZA4l",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Debug"
      ],
      "metadata": {
        "id": "V7ef3WNNVxXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_standard.pth\")\n",
        "model_path = os.path.join(Config.model_save_path, f\"{Config.model_name}_energy.pth\")\n",
        "\n",
        "model_to_diag = create_model()\n",
        "model_to_diag.load_state_dict(torch.load(model_path, map_location=Config.device))\n",
        "model_to_diag.eval()\n",
        "\n",
        "id_scores, ood_scores = [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, _ in tqdm(id_test_loader, desc=\"Calculating ID scores\"):\n",
        "        id_scores.extend(get_energy_score(model_to_diag(inputs.to(Config.device))).cpu().numpy())\n",
        "\n",
        "    for inputs, _ in tqdm(ood_test_loader, desc=f\"Calculating OOD scores for {Config.ood_dataset}\"):\n",
        "        ood_scores.extend(get_energy_score(model_to_diag(inputs.to(Config.device))).cpu().numpy())\n",
        "\n",
        "print(f\"\\nAggregate results for model: {model_path}\")\n",
        "print(f\"Overall mean ID energy: {np.mean(id_scores):.2f} (+/-: {np.std(id_scores):.2f})\")\n",
        "print(f\"Overall mean OOD energy: {np.mean(ood_scores):.2f} (+/-: {np.std(ood_scores):.2f})\")"
      ],
      "metadata": {
        "id": "3qED6LmO-Fcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c57d98-e890-49b6-82a7-e9a57f21727b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating MobileNetV3 model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating ID scores: 100%|| 99/99 [00:26<00:00,  3.78it/s]\n",
            "Calculating OOD scores for DTD: 100%|| 8/8 [00:02<00:00,  2.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Aggregate results for model: ./models/mobilenetv3_energy.pth\n",
            "Overall mean ID energy: -12.27 (+/-: 4.36)\n",
            "Overall mean OOD energy: -6.38 (+/-: 2.01)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 31089,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "sYZF4TScQdEN",
        "EdqINYpj-Jog",
        "V7ef3WNNVxXo"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}